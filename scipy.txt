import numpy as np
import torch, torchvision
import time, warnings
import os
from torch.optim import optimizer
from torch.nn.functional import relu
from matplotlib import pyplot as plt
warnings.filterwarnings("ignore") 
'''Define miscellaneous stuff'''
def stat_cuda(msg=''):
    print('GPU memory usage ' + msg + ':')
    print('allocated: %dM (max %dM), cached: %dM (max %dM)'
          % (torch.cuda.memory_allocated() / 1024 / 1024,
             torch.cuda.max_memory_allocated() / 1024 / 1024,
             torch.cuda.memory_reserved() / 1024 / 1024,
             torch.cuda.max_memory_reserved() / 1024 / 1024))

device = torch.device('cpu')
basedir = 'temp/'
if not os.path.isdir(basedir):
    os.makedirs(basedir)

SEED = 1234
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True


class Timer(object):
    def __init__(self, name=None):
        self.name = name

    def __enter__(self):
        self.tstart = time.time()

    def __exit__(self, type, value, traceback):
        if self.name:
            print('[%s]' % self.name,)
        print('Elapsed: %s' % (time.time() - self.tstart))

def get_vgg_layers(config, batch_norm=True):
    
    layers = []
    in_channels = 1
    
    for c in config:
        assert c == 'M' or isinstance(c, int)
        if c == 'M':
            layers += [torch.nn.MaxPool2d(kernel_size = 2)]
        else:
            conv2d = torch.nn.Conv2d(in_channels, c, kernel_size = 3, padding = 1)
            if batch_norm:
                layers += [conv2d, torch.nn.BatchNorm2d(c), torch.nn.ReLU(inplace = True)]
            else:
                layers += [conv2d, torch.nn.ReLU(inplace = True)]
            in_channels = c
            
    return torch.nn.Sequential(*layers)
vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']
vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']
custom_config = [32, 'M', 64, 'M']
#set up dataset, dataloader
dataset = torchvision.datasets.FashionMNIST(root = '.data', train=True, download=True, transform=torchvision.transforms.ToTensor())
batch_size = len(dataset)
dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)
dataiter = iter(dataloader)
images, _ = dataiter.next()
mean, std = images.mean(), images.std()
del(images, dataiter, dataloader, batch_size)
# mean, std = 0.2860, 0.3530

transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean, std)])
dataset = torchvision.datasets.FashionMNIST(root = '.data', train=True, download=True, transform=transform)

batch_size = 64
dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)
dataiter = iter(dataloader)

#define network
class VGGRegressionModel(torch.nn.Module):
    def __init__(self, config):
        super(VGGRegressionModel, self).__init__()
        self.features = get_vgg_layers(config)

        self.classifier = torch.nn.Sequential(
            torch.nn.Linear(64*7*7, 4096),
            torch.nn.ReLU(inplace = True),
            torch.nn.Linear(4096, 1024),
            torch.nn.ReLU(inplace = True),
            torch.nn.Dropout(0.3),
            torch.nn.ReLU(inplace = True),
            torch.nn.Linear(1024, 256),
            torch.nn.ReLU(inplace = True),
            torch.nn.Linear(256, 10),
        )

    def forward(self, x):
        # print('before convolution: ', x.shape)
        x = self.features(x)
        # print('after convolution: ', x.shape)
        x = x.view(x.shape[0], -1)
        # exit('exited in VGGRegressionModel')
        x = self.classifier(x)
        return x

'''Define model, optimizer, error function'''
model = VGGRegressionModel(custom_config).to(device)
optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)
criterion = torch.nn.CrossEntropyLoss()

epoch_init = 9
n_epochs = 10
'''Load model checkpoint'''
if epoch_init>=0:
    checkpoint = torch.load(basedir + 'model_e%d.pt' % (epoch_init))
    epoch = checkpoint['epoch']
    losses = checkpoint['losses']
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    del(checkpoint)
else:
    losses = []


'''Train'''
iter_num = int(np.ceil(len(dataset)/batch_size))
with Timer('training phase'):
    for epoch in range(epoch_init+1, n_epochs):
        epoch_loss = torch.tensor([])
        for batch_index, (inputs, labels) in enumerate(dataloader):
            optimizer.zero_grad()
            predictions = model(inputs.to(device))
            l = criterion(predictions, labels.to(torch.long).to(device))
            l.backward()
            optimizer.step()
            epoch_loss = torch.cat((epoch_loss, torch.tensor(l.item()).unsqueeze(0)), dim=0)
            if batch_index%300 == 0:
                print(f'Loss = {l.item():.4f} at epoch {epoch} and batch {batch_index}/{iter_num}')
                stat_cuda()

        losses.append(epoch_loss.mean())
        '''Save model checkpoint'''
        torch.save({
                    'epoch': epoch,
                    'losses': losses,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict()
                    }, basedir + 'model_e%d.pt' % (epoch))

'''Plot Loss'''
plt.plot(losses[0:])
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.savefig(basedir + 'loss.png') 

'''Evaluate Network on testset'''
print('Evaluating on testset')
#set up testset
dataset = torchvision.datasets.FashionMNIST(root = '.data', train=False, download=True, transform=torchvision.transforms.ToTensor())
batch_size = len(dataset)
dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)
dataiter = iter(dataloader)
images, _ = dataiter.next()
mean, std = images.mean(), images.std()
del(images, dataiter, dataloader, batch_size)

transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean, std)])
dataset = torchvision.datasets.FashionMNIST(root = '.data', train=False, download=True, transform=transform)

batch_size = 128
dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)
dataiter = iter(dataloader)


accuracy = 0
with torch.no_grad():
    prediction_list, label_list = [], []
    for idx in range(len(dataset)):
        input, img_id = dataset[idx]
        prediction_list.append(model(input.unsqueeze(0).to(device)).cpu().argmax().item())
        label_list.append(img_id)
        if label_list[idx]==prediction_list[idx]: accuracy+=1
accuracy /= len(dataset)
print(accuracy)